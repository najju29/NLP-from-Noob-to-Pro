{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GloVe Word Embeddings with PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijrQpDETHNBD"
      },
      "source": [
        "# What are Word Embeddings ?\n",
        "- Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.\n",
        "- They are a distributed representation for text that is perhaps one of the key breakthroughs for the impressive performance of deep learning methods on challenging **Natural Language Processing** problems.\n",
        "- <img src=\"https://miro.medium.com/max/1838/1*OEmWDt4eztOcm5pr2QbxfA.png\" width=\"800\" height=\"300\">\n",
        "- You can see in the above image that the formed word embeddings indicate the relationship in between them in terms of distance more than the normal one-hot encoding vevtors.\n",
        "- This relation calculating metric can be anything like cosine similarity, Manhattan distance, Euclidean Distance etc.\n",
        "- We can even manually enter this normalized scores based on their similarity to make better word embeddings.\n",
        "- These word embeddings can be made Manual or we can use Pre-trained ones like Word2Vec, Glove(100d, 200d, 300d), Gensim models and Etc.\n",
        "- Let us understand how it works and why is it better in a while. Firstly we will be looking at the custom word embeddings and would be moving on to the next one with a fresh notebook.\n",
        "# How are Embeddings made ? \n",
        "- <img src=\"https://www.biorxiv.org/content/biorxiv/early/2018/05/21/327601/F1.large.jpg\" width=\"800\" height=\"300\">\n",
        "- Here before LSTM Layer what ever the **matrix** you are watching is what called as an Embedding layer.\n",
        "- For each Word or Token from the embedding there is a **1-D vector** assosiated with it which is of len **Embedded Length**.\n",
        "- Here the Length of the Embedded layer can be of user's choice.\n",
        "- Basically this matrix will always be shape **Total Vocabulary X Total Vocabulary**.\n",
        "- Now let us move on to the Modelling part where we can easily understand whats happening beneath.\n",
        "\n",
        "# What are GloVe Embeddings\n",
        "- GloVe stands for **(Glo- Global , Ve- Vectors)** which was introduced by **Stanford**.\n",
        "- GloVe (Global Vectors for Word Representation) is an alternate method to create word embeddings. It is based on matrix factorization techniques on the word-context matrix. A large matrix of co-occurrence information is constructed and you count each “word” (the rows), and how frequently we see this word in some “context” (the columns) in a large corpus.\n",
        "- According to thier page ***GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.**\n",
        "- The Context that GloVe brings in to system is what makes it **State of the Art**. Look at the below picture to know how context gives you meaning to a sentence.\n",
        "- <img src=\"http://kavita-ganesan.com/wp-content/uploads/257.png\" width=\"600\" height=\"300\">\n",
        "- We have bunch of different variants for glove depending on their Embedding lengths. Below are some of its variants.\n",
        "-   *glove.42B.300d*,\n",
        "-   *glove.840B.300d*,\n",
        "-   *glove.twitter.27B.25d*\n",
        "-   *glove.twitter.27B.50d*\n",
        "-   *glove.twitter.27B.100d*\n",
        "-   *glove.twitter.27B.200d*\n",
        "-   *glove.6B.50d*\n",
        "-   *glove.6B.100d*\n",
        "-   *glove.6B.200d*\n",
        "-   *glove.6B.300d*\n",
        "- Read more about it here - [GloVe by Stanford](https://nlp.stanford.edu/projects/glove/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExfQmbyTmVyF"
      },
      "source": [
        "# GloVe Word Embedding with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8yq8O9zUvfG"
      },
      "source": [
        "## Loading and Splitting Data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe4CebcwE-VJ"
      },
      "source": [
        "# For this we will firstly import All Important Libraries\n",
        "\n",
        "# Data handling libraries(Linear Algebra)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data Visualization and Managing libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "# importing Torch\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy import data\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdgBvzzmQo8U"
      },
      "source": [
        "- **TorchText:**Generic data loaders, abstractions, and iterators for text (including vocabulary and word vectors) torchtext.\n",
        "- **Note**: From torchtext > 0.9.0 release notes, *torchtext.data* is now officially moved into the *torchtext.legacy.data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6uS2DD1TNa5"
      },
      "source": [
        "# For regenrating the same results\n",
        "SEED = 2019\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# Setting up Cuda algorithms\n",
        "torch.backends.cudnn.deterministic = True  \n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr--LqfIXYH8"
      },
      "source": [
        "- Now Let us load the data and split it accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RK5qUBJXXV-"
      },
      "source": [
        "imdb_data = pd.read_csv('/content/drive/MyDrive/IMDB Dataset.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "jpo3DQTFXpkj",
        "outputId": "a61a16b7-de24-44ba-bb86-8c6b90828eb3"
      },
      "source": [
        "imdb_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT9I_AR4Xuy6"
      },
      "source": [
        "- Now let us convert the target to label encodings and split the data for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEiafIHwXXNW",
        "outputId": "c4cd4f85-ed2b-4b55-9648-d763e8fdb0e5"
      },
      "source": [
        "imdb_data['sentiment'].unique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive', 'negative'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyUslbV2XXAY"
      },
      "source": [
        "imdb_data['sentiment']=imdb_data['sentiment'].map({'positive':1,'negative':0})"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hItwVjlYX6Md",
        "outputId": "9d165132-a4cf-4706-dea4-a89f5823f929"
      },
      "source": [
        "# Unique values in target after the Label Mapping\n",
        "imdb_data['sentiment'].unique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "2HnczT1z1aLu",
        "outputId": "77c40551-a53e-4298-aeaf-d95a5bc5f88a"
      },
      "source": [
        "sns.countplot(imdb_data['sentiment'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5fa2c7e990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2FnxJCNX6P4"
      },
      "source": [
        "train_data, valid_data = train_test_split(imdb_data, test_size = 0.3)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1OWWmouX6Sj",
        "outputId": "d5853416-0761-4cc2-b6b2-204bc89ded1a"
      },
      "source": [
        "print(f'Shape of the Training data is :{train_data.shape}')\n",
        "print(f'Shape of the Validation data is :{valid_data.shape}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the Training data is :(35000, 2)\n",
            "Shape of the Validation data is :(15000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2V1OkO2Szal"
      },
      "source": [
        "- Now let us define some fileds where preprocessing of the text happens.\n",
        "- **data.Field**:torchtext.data.Field is a base datatype of PyTorch Text that helps with text preprocessing: tokenization, lowercasting, padding, umericalizaion and Building vocabulary.\n",
        " - **tokenize**: specifies the way of tokenizing the sentence i.e. converting sentence to words.\n",
        " - **batch_first**: The first dimension of input and output is always batch size\n",
        "- **data.LabelField**: LabelField object is a special case of Field object which is used only for the classification tasks. Its only use is to set the unk_token and sequential to None by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jtkm39L2TNjO"
      },
      "source": [
        "text_field = data.Field(tokenize='spacy',include_lengths=True, unk_token='<unk>')\n",
        "\n",
        "label_field = data.LabelField(dtype = torch.float)\n",
        "# or use : LABEL = data.Field(sequential=False, use_vocab=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si6uMeIp8TAS"
      },
      "source": [
        "- Next we create a **DataFrameDataset** class which will allow us to load the data and the target-labels as a **DataSet** using a DataFrame as a source of data. We will create a vocabulary using the training dataset and then pass the training and validation datasets to the iterator later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpnU_rzoY1M5"
      },
      "source": [
        "# source : https://gist.github.com/lextoumbourou/8f90313cbc3598ffbabeeaa1741a11c8\n",
        "# to use DataFrame as a Data source\n",
        "class DataFrameDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, df, fields, is_test=False, **kwargs):\n",
        "        examples = []\n",
        "        for i, row in df.iterrows():\n",
        "            label = row.sentiment if not is_test else None\n",
        "            text = row.review\n",
        "            examples.append(data.Example.fromlist([text, label], fields))\n",
        "\n",
        "        super().__init__(examples, fields, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return len(ex.review)\n",
        "\n",
        "    @classmethod\n",
        "    def splits(cls, fields, train_df, val_df=None, test_df=None, **kwargs):\n",
        "        train_data, val_data, test_data = (None, None, None)\n",
        "        data_field = fields\n",
        "\n",
        "        if train_df is not None:\n",
        "            train_data = cls(train_df.copy(), data_field, **kwargs)\n",
        "        if val_df is not None:\n",
        "            val_data = cls(val_df.copy(), data_field, **kwargs)\n",
        "        if test_df is not None:\n",
        "            test_data = cls(test_df.copy(), data_field, True, **kwargs)\n",
        "\n",
        "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDIsfn4jBOke"
      },
      "source": [
        "- Now we have to make a list of tuples in which the first element would indicate the name of the column and then the next element would be a function instance of Field or LabelField.\n",
        "- Let us firstly make it and see how it looks like..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E7oclugBKie"
      },
      "source": [
        "# For text we have text_field object that we declared previously and same goes for the target field.\n",
        "column_fields = [('review',text_field),('sentiment', label_field)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3wQekoOgmW0"
      },
      "source": [
        "- **NOTE:** The serial of the fields in above column field should be the same as it is in the dataset or else you may find some error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H0CDeNISZgK"
      },
      "source": [
        "- Let us split the data into Training and Test splits using the Dataset Class that we have written in the above cell. Let us try to unpack them and divide the dataset into Training and test Splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9niSG9_B-0B"
      },
      "source": [
        "train_ds, val_ds = DataFrameDataset.splits(column_fields, train_df=train_data, val_df=valid_data)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ezSFVbqpLp9"
      },
      "source": [
        "- Let us have a look at how our preprocessing is being done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkeM1kM-pLE3",
        "outputId": "7dc78a36-6e52-4758-e26c-990173d03a70"
      },
      "source": [
        "# Printing our processed text\n",
        "print(vars(train_ds[15]))\n",
        "\n",
        "# Checking the type of our text\n",
        "print(type(train_ds[15]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'review': ['Bone', 'Eater', 'is', 'set', 'in', 'a', 'small', 'desert', 'town', 'in', 'Alabama', 'where', 'property', 'developer', 'Dick', 'Krantz', '(', 'Jim', 'Storm', ')', 'is', 'financing', 'the', 'building', 'of', 'a', 'huge', 'resort', '.', 'Late', 'one', 'night', 'three', 'of', 'his', 'workers', 'Riley', '(', 'Timothy', 'Starks', ')', ',', 'Hansen', '(', 'Adrian', 'Alvarado', ')', '&', 'Miller', '(', 'Paul', 'Rae', ')', 'are', 'digging', 'foundations', 'in', 'the', 'desert', 'when', 'they', 'unearth', 'what', 'looks', 'like', 'a', 'tomahawk', 'axe', ',', 'unfortunately', 'for', 'them', 'an', 'ancient', 'Native', 'American', 'demon', 'called', 'the', 'bone', 'eater', 'comes', 'along', '&', 'kills', 'them', '.', 'Local', 'Sheriff', 'Steve', 'Evans', '(', 'Bruce', 'Boxleitner', ')', 'soon', 'has', 'Krantz', 'breathing', 'down', 'his', 'neck', 'as', 'the', 'construction', 'of', 'his', 'resort', 'grinds', 'to', 'a', 'halt', ',', 'Sheriff', 'Evans', 'also', 'has', 'to', 'deal', 'with', 'the', 'bone', 'eater', 'demon', 'as', 'it', 'kills', 'anyone', 'it', 'comes', 'across', '...', '<br', '/><br', '/>You', 'know', 'I', 'consider', 'myself', 'a', 'fairly', 'big', 'fan', 'of', 'the', 'horror', '&', 'sci', '-', 'fi', 'genre', ',', 'I', 'certainly', 'do', \"n't\", 'think', 'my', 'opinion', 'is', 'worth', 'more', 'than', 'anyone', 'else', \"'s\", '(', 'unlike', 'many', 'here', 'on', 'the', 'IMDb', '...', ')', 'but', 'please', 'believe', 'me', 'when', 'I', 'say', 'that', 'Bone', 'Eater', 'is', 'the', 'worst', 'Sci', '-', 'Fi', 'Channel', \"'\", 'Creature', 'Feature', \"'\", 'I', 'have', 'ever', 'seen', '&', 'it', \"'s\", 'up', 'against', 'some', 'damned', 'strong', 'competition', '.', 'As', 'a', 'horror', '&', 'sci', '-', 'fi', 'fan', 'there', 'are', 'two', 'names', 'that', 'when', 'involved', 'with', 'a', 'film', 'send', 'shudders', 'down', 'my', 'spine', 'in', 'anticipation', 'of', 'how', 'bad', 'it', 'will', 'turn', 'out', ',', 'those', 'names', 'are', 'Jesus', \"'\", 'I', 'have', 'no', 'talent', \"'\", 'Franco', 'who', 'had', 'nothing', 'to', 'do', 'with', 'Bone', 'Eater', '&', 'Jim', 'Wynorski', 'who', 'directed', 'the', 'absolute', 'disaster', 'that', 'is', 'Bone', 'Eater', '.', 'In', 'fact', 'Bone', 'Eater', 'is', 'so', 'bad', 'Wynorski', 'hid', 'under', 'the', 'pseudonym', 'Bob', 'Robertson', ',', 'when', 'a', 'director', 'as', 'bad', 'as', 'Wynorski', 'hides', 'under', 'a', 'pseudonym', 'you', 'know', 'the', 'film', 'must', 'be', 'bad', '.', 'Where', 'do', 'I', 'even', 'start', '?', 'Bone', 'Eater', 'is', 'quite', 'simply', 'the', 'worst', 'film', 'I', 'have', 'seen', 'this', 'year', '&', 'is', 'so', 'bad', 'it', \"'s\", 'untrue', ',', 'the', 'story', 'is', 'awful', ',', 'the', 'script', 'is', 'sloppy', '(', 'at', 'one', 'point', 'Sheriff', 'Evans', 'tells', 'Kia', 'to', 'meet', 'him', 'at', 'the', 'hospital', 'but', 'when', 'they', 'meet', 'there', 'later', 'he', 'acts', 'surprised', '&', 'says', \"'\", 'what', 'are', 'you', 'doing', 'here', '?', \"'\", ',', 'at', 'one', 'point', 'Sheriff', 'Evans', 'triumphantly', 'claims', 'that', 'we', 'are', 'in', 'the', 'twentieth', 'century', '&', 'that', 'ancient', 'Native', 'American', 'demons', 'are', 'nonsense', 'although', 'actually', 'we', 'are', 'in', 'the', 'twenty', 'first', 'century', 'now', ',', 'there', \"'s\", 'a', 'part', 'when', 'a', 'woman', 'tells', 'in', 'flashback', 'the', 'story', 'where', 'three', 'men', 'awaken', 'the', 'Bone', 'Eater', '&', 'it', 'kills', 'them', 'but', 'since', 'it', 'killed', 'all', 'three', 'of', 'them', 'how', 'did', 'anyone', 'else', 'know', 'about', 'it', 'for', 'it', 'to', 'be', 'passed', 'down', 'in', 'legend', '?', ')', '&', 'at', 'times', 'it', 'gets', 'more', 'than', 'a', 'little', 'bit', 'embarrassing', '.', 'The', 'character', \"'s\", 'are', 'horrible', 'clichés', ',', 'the', 'small', 'town', 'Sheriff', 'who', 'saves', 'the', 'day', ',', 'his', 'daughter', 'becomes', 'involved', 'which', 'adds', 'some', 'personal', 'motivation', '&', 'as', 'for', 'the', 'Native', 'Americans', 'there', \"'s\", 'an', 'old', 'wise', 'man', ',', 'a', 'young', 'hot', 'head', 'who', 'hates', \"'\", 'white', 'man', \"'\", '&', 'a', 'young', 'woman', 'who', 'is', 'the', 'voice', 'of', 'reason', 'between', 'the', 'two', 'who', 'have', 'names', 'like', 'Storm', 'Cloud', '&', 'Black', 'Hawk', '.', 'The', 'film', 'is', 'as', 'boring', 'as', 'hell', ',', 'nothing', 'happens', ',', 'the', 'story', 'is', 'awful', ',', 'it', \"'s\", 'full', 'of', 'plot', 'holes', '&', 'lapses', 'in', 'any', 'sort', 'of', 'logic', ',', 'the', 'set', '-', 'pieces', 'are', 'terrible', ',', 'there', \"'s\", 'no', 'horror', 'or', 'gore', 'or', 'suspense', 'or', 'mystery', '&', 'Bone', 'Eater', 'is', 'just', 'the', 'sort', 'of', 'film', 'that', 'makes', 'you', 'lose', 'the', 'will', 'to', 'live.<br', '/><br', '/>Bone', 'Eater', 'has', 'some', 'of', 'the', 'worst', 'CGI', 'computer', 'effects', 'I', \"'ve\", 'seen', 'in', 'a', 'while', ',', 'from', 'the', 'daft', 'looking', 'stiff', 'moving', 'bone', 'eater', 'creature', 'itself', 'which', 'is', 'just', 'a', 'selection', 'of', 'bones', 'magically', 'held', 'together', 'to', 'a', 'motorbike', 'jumping', 'a', 'large', 'gap', 'to', 'an', 'awful', 'CGI', 'truck', 'crashing', 'over', 'the', 'edge', 'of', 'a', 'cliff', 'to', 'a', 'van', 'being', 'tossed', 'to', 'one', 'side', 'by', 'the', 'bone', 'eater', '.', 'Whenever', 'the', 'bone', 'eater', 'needs', 'to', 'get', 'some', 'speed', 'up', 'he', 'causes', 'a', 'large', 'horse', 'to', 'form', 'from', 'the', 'sand', '&', 'dust', '&', 'rides', 'it', '!', 'In', 'principal', 'this', 'is', 'actually', 'quite', 'a', 'neat', 'idea', 'but', 'it', 'looks', 'awful', '&', 'the', 'scenes', 'even', 'have', 'cheesy', 'cowboy', 'music', 'on', 'the', 'soundtrack', '!', 'There', 'is', 'one', 'pointless', 'scene', 'at', 'the', 'end', 'when', 'Sheriff', 'Evans', 'cuts', 'his', 'own', 'arm', '(', 'why', '?', ')', '&', 'it', 'bleeds', 'but', 'apart', 'from', 'that', 'there', 'is', \"n't\", 'a', 'single', 'drop', 'of', 'blood', 'in', 'the', 'thing', ',', 'whenever', 'the', 'bone', 'eater', 'kills', 'someone', 'they', 'usually', 'just', 'disappear', 'in', 'a', 'cloud', 'of', 'dust', ',', 'boring', '.', 'The', 'hilariously', 'goofy', 'climatic', 'showdown', 'between', 'Sheriff', 'Evans', '&', 'the', 'bone', 'eater', 'has', 'to', 'be', 'seen', 'to', 'be', 'believed', ',', 'Sheriff', 'Evans', 'goes', 'native', 'on', 'horseback', 'complete', 'with', 'tribal', 'war', 'paint', 'on', 'his', 'face', 'while', 'the', 'bone', 'eater', 'also', 'rides', 'his', 'dust', 'horse', '&', 'they', 'have', 'a', 'sort', 'of', 'jousting', 'contest', 'which', 'is', 'just', 'to', 'bad', 'to', 'describe', 'properly.<br', '/><br', '/>With', 'a', 'supposed', 'budget', 'of', 'about', '$', '700,000', 'Bone', 'Eater', 'is', 'filmed', 'in', 'a', 'very', 'bland', ',', 'forgettable', '&', 'flat', 'way', ',', 'there', \"'s\", 'no', 'sense', 'of', 'style', 'here', 'at', 'all', '.', 'The', 'majority', 'of', 'the', 'film', 'takes', 'place', 'in', 'bright', 'sunlight', '&', 'if', 'you', 'watch', 'it', 'on', 'a', 'decent', 'telly', 'then', 'the', 'desert', 'scenery', 'is', 'quite', 'nice', 'on', 'occasion', '.', 'There', 'are', 'several', 'veteran', \"'\", 'known', \"'\", 'actors', 'really', 'slumming', 'it', 'here', ',', 'Boxleitner', 'plays', 'exactly', 'the', 'same', 'role', 'as', 'in', 'the', 'similarly', 'themed', 'but', 'much', 'better', \"'\", 'Creature', 'Feature', \"'\", 'Snakehead', 'Terror', '(', '2004', ')', ',', 'William', 'Katt', 'will', 'obviously', 'put', 'his', 'name', 'to', 'any', 'crap', 'as', 'long', 'as', 'he', 'gets', 'paid', 'while', 'ex', 'Star', 'Trek', 'man', 'Walter', 'Koenig', 'must', 'be', 'really', 'desperate', 'to', 'agree', 'to', 'appear', 'in', 'this.<br', '/><br', '/>Bone', 'Eater', 'is', 'a', 'truly', 'atrocious', \"'\", 'Creature', 'Feature', \"'\", ',', 'there', \"'s\", 'really', 'not', 'much', 'more', 'you', 'can', 'say', 'about', 'it', 'other', 'than', 'to', 'steer', 'well', 'clear', 'of', 'it', '.', 'The', 'worst', 'film', 'ever', 'to', 'appear', 'on', 'the', 'Sci', '-', 'Fi', 'Channel', '&', 'that', \"'s\", 'saying', 'something', ',', 'is', \"n't\", 'it', '?'], 'sentiment': 0}\n",
            "<class 'torchtext.legacy.data.example.Example'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9dwVmxSUKy4"
      },
      "source": [
        "- As we are done with all the Dataloading tasks now let us set parameters for setting a sentence length and frequency of the words we have in our dataset.\n",
        "## Using GloVe Embeddings\n",
        "- We have alot of variants in Glove embedings lets have a look at them.\n",
        "-   *glove.42B.300d*,\n",
        "-   *glove.840B.300d*,\n",
        "-   *glove.twitter.27B.25d*\n",
        "-   *glove.twitter.27B.50d*\n",
        "-   *glove.twitter.27B.100d*\n",
        "-   *glove.twitter.27B.200d*\n",
        "-   *glove.6B.50d*\n",
        "-   *glove.6B.100d*\n",
        "-   *glove.6B.200d*\n",
        "-   *glove.6B.300d*\n",
        "- We will be using the **glove.6B.100d** with embedding dimensions fixed to 100 dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk0XansDB-4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c510133-d791-4b0b-8b9a-d77ea95d499a"
      },
      "source": [
        "#initialize glove embeddings\n",
        "text_field.build_vocab(train_ds,\n",
        "                       vectors = 'glove.6B.100d',\n",
        "                       min_freq=5)# use vectors as a parameter to consider pretrained embeddings(vectors = \"glove.6B.100d\")  \n",
        "label_field.build_vocab(train_ds)\n",
        "\n",
        "#No. of unique words in our text corpus\n",
        "print(\"Size of TEXT Corpus:\",len(text_field.vocab))\n",
        "\n",
        "#No. of unique tokens in label\n",
        "print('\\n')\n",
        "print(\"Size of LABEL vocabulary:\",len(label_field.vocab))\n",
        " "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.37MB/s]                           \n",
            "100%|█████████▉| 399596/400000 [00:13<00:00, 29192.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Size of TEXT Corpus: 42372\n",
            "\n",
            "\n",
            "Size of LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOxMjr9jhAXz"
      },
      "source": [
        "- We have succesfully made our vocabulary for our train data.\n",
        "- Let us have a look at the top 10 most occuring words in our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1VY1NRiB-8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c500164d-4e95-4e38-cbd7-43bc962def6f"
      },
      "source": [
        "#Commonly used words\n",
        "top_ten_words = text_field.vocab.freqs.most_common(10) # Fetches out the top 1o words using .most_common() method\n",
        "for top_words in top_ten_words:# Looping through words\n",
        "    print(f'Word \"{top_words[0]}\" repeated {top_words[1]} times in the whole corpus')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word \"the\" repeated 401840 times in the whole corpus\n",
            "Word \",\" repeated 378661 times in the whole corpus\n",
            "Word \".\" repeated 328134 times in the whole corpus\n",
            "Word \"a\" repeated 216399 times in the whole corpus\n",
            "Word \"and\" repeated 216361 times in the whole corpus\n",
            "Word \"of\" repeated 200287 times in the whole corpus\n",
            "Word \"to\" repeated 185243 times in the whole corpus\n",
            "Word \"is\" repeated 150142 times in the whole corpus\n",
            "Word \"in\" repeated 122182 times in the whole corpus\n",
            "Word \"I\" repeated 108335 times in the whole corpus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0nwXAJPrHv4"
      },
      "source": [
        "- We can see the top 10 words of our corpus.\n",
        "- Now let us look at Dictionary of the word corpus that we just made right now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C27m4W68YyOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8affe7f3-9aae-4db8-f215-417aaa405ca1"
      },
      "source": [
        "#Word dictionary\n",
        "text_field.vocab.stoi # \"stoi\" stands for string to Index."
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x7f5f2f24edd0>>,\n",
              "            {'<unk>': 0,\n",
              "             '<pad>': 1,\n",
              "             'the': 2,\n",
              "             ',': 3,\n",
              "             '.': 4,\n",
              "             'a': 5,\n",
              "             'and': 6,\n",
              "             'of': 7,\n",
              "             'to': 8,\n",
              "             'is': 9,\n",
              "             'in': 10,\n",
              "             'I': 11,\n",
              "             'it': 12,\n",
              "             'that': 13,\n",
              "             '\"': 14,\n",
              "             \"'s\": 15,\n",
              "             'this': 16,\n",
              "             '-': 17,\n",
              "             '/><br': 18,\n",
              "             'was': 19,\n",
              "             'with': 20,\n",
              "             'as': 21,\n",
              "             'movie': 22,\n",
              "             'for': 23,\n",
              "             'film': 24,\n",
              "             'The': 25,\n",
              "             'but': 26,\n",
              "             'on': 27,\n",
              "             \"n't\": 28,\n",
              "             '(': 29,\n",
              "             ')': 30,\n",
              "             'you': 31,\n",
              "             'are': 32,\n",
              "             'not': 33,\n",
              "             'have': 34,\n",
              "             'his': 35,\n",
              "             'be': 36,\n",
              "             'one': 37,\n",
              "             'he': 38,\n",
              "             '!': 39,\n",
              "             'at': 40,\n",
              "             'by': 41,\n",
              "             'all': 42,\n",
              "             'an': 43,\n",
              "             'who': 44,\n",
              "             'from': 45,\n",
              "             'they': 46,\n",
              "             'like': 47,\n",
              "             'so': 48,\n",
              "             'or': 49,\n",
              "             'has': 50,\n",
              "             \"'\": 51,\n",
              "             'about': 52,\n",
              "             'her': 53,\n",
              "             'out': 54,\n",
              "             'It': 55,\n",
              "             'just': 56,\n",
              "             'do': 57,\n",
              "             '?': 58,\n",
              "             'some': 59,\n",
              "             'good': 60,\n",
              "             'more': 61,\n",
              "             'would': 62,\n",
              "             'very': 63,\n",
              "             'up': 64,\n",
              "             'what': 65,\n",
              "             'This': 66,\n",
              "             'there': 67,\n",
              "             'time': 68,\n",
              "             'can': 69,\n",
              "             'when': 70,\n",
              "             'if': 71,\n",
              "             'which': 72,\n",
              "             'had': 73,\n",
              "             'really': 74,\n",
              "             'see': 75,\n",
              "             'their': 76,\n",
              "             'only': 77,\n",
              "             'story': 78,\n",
              "             'were': 79,\n",
              "             'she': 80,\n",
              "             'even': 81,\n",
              "             'no': 82,\n",
              "             'my': 83,\n",
              "             'me': 84,\n",
              "             'did': 85,\n",
              "             'does': 86,\n",
              "             '...': 87,\n",
              "             'than': 88,\n",
              "             'much': 89,\n",
              "             'been': 90,\n",
              "             ':': 91,\n",
              "             'could': 92,\n",
              "             'get': 93,\n",
              "             'into': 94,\n",
              "             'well': 95,\n",
              "             'will': 96,\n",
              "             'other': 97,\n",
              "             'people': 98,\n",
              "             'bad': 99,\n",
              "             'we': 100,\n",
              "             'because': 101,\n",
              "             'him': 102,\n",
              "             'great': 103,\n",
              "             'most': 104,\n",
              "             'first': 105,\n",
              "             'made': 106,\n",
              "             '<': 107,\n",
              "             'them': 108,\n",
              "             'make': 109,\n",
              "             'br': 110,\n",
              "             'how': 111,\n",
              "             'also': 112,\n",
              "             'way': 113,\n",
              "             'its': 114,\n",
              "             'movies': 115,\n",
              "             'any': 116,\n",
              "             'too': 117,\n",
              "             '/>The': 118,\n",
              "             'think': 119,\n",
              "             'characters': 120,\n",
              "             'character': 121,\n",
              "             'films': 122,\n",
              "             'then': 123,\n",
              "             ';': 124,\n",
              "             'seen': 125,\n",
              "             'being': 126,\n",
              "             'watch': 127,\n",
              "             'many': 128,\n",
              "             'But': 129,\n",
              "             'plot': 130,\n",
              "             'two': 131,\n",
              "             'acting': 132,\n",
              "             'never': 133,\n",
              "             'know': 134,\n",
              "             'And': 135,\n",
              "             'life': 136,\n",
              "             'love': 137,\n",
              "             'over': 138,\n",
              "             'where': 139,\n",
              "             'show': 140,\n",
              "             'little': 141,\n",
              "             'off': 142,\n",
              "             'after': 143,\n",
              "             'best': 144,\n",
              "             'ever': 145,\n",
              "             'your': 146,\n",
              "             'better': 147,\n",
              "             'scene': 148,\n",
              "             'A': 149,\n",
              "             '*': 150,\n",
              "             'say': 151,\n",
              "             'end': 152,\n",
              "             'i': 153,\n",
              "             'He': 154,\n",
              "             'should': 155,\n",
              "             'There': 156,\n",
              "             'scenes': 157,\n",
              "             'In': 158,\n",
              "             'still': 159,\n",
              "             'such': 160,\n",
              "             \"'ve\": 161,\n",
              "             'man': 162,\n",
              "             'something': 163,\n",
              "             '/': 164,\n",
              "             'here': 165,\n",
              "             'these': 166,\n",
              "             'through': 167,\n",
              "             'go': 168,\n",
              "             'back': 169,\n",
              "             'If': 170,\n",
              "             'real': 171,\n",
              "             'those': 172,\n",
              "             \"'m\": 173,\n",
              "             'thing': 174,\n",
              "             'actors': 175,\n",
              "             'watching': 176,\n",
              "             'years': 177,\n",
              "             'funny': 178,\n",
              "             'makes': 179,\n",
              "             'old': 180,\n",
              "             'find': 181,\n",
              "             'work': 182,\n",
              "             'going': 183,\n",
              "             '--': 184,\n",
              "             'actually': 185,\n",
              "             'same': 186,\n",
              "             'lot': 187,\n",
              "             'before': 188,\n",
              "             'few': 189,\n",
              "             'though': 190,\n",
              "             'look': 191,\n",
              "             'why': 192,\n",
              "             'director': 193,\n",
              "             'while': 194,\n",
              "             \"'re\": 195,\n",
              "             'part': 196,\n",
              "             '&': 197,\n",
              "             'ca': 198,\n",
              "             '/>I': 199,\n",
              "             'nothing': 200,\n",
              "             'cast': 201,\n",
              "             'another': 202,\n",
              "             'down': 203,\n",
              "             'again': 204,\n",
              "             'want': 205,\n",
              "             'got': 206,\n",
              "             'quite': 207,\n",
              "             'every': 208,\n",
              "             'pretty': 209,\n",
              "             'around': 210,\n",
              "             'fact': 211,\n",
              "             'things': 212,\n",
              "             'seems': 213,\n",
              "             'thought': 214,\n",
              "             'enough': 215,\n",
              "             'own': 216,\n",
              "             'long': 217,\n",
              "             'horror': 218,\n",
              "             'between': 219,\n",
              "             'now': 220,\n",
              "             'take': 221,\n",
              "             'give': 222,\n",
              "             'must': 223,\n",
              "             'young': 224,\n",
              "             'world': 225,\n",
              "             'us': 226,\n",
              "             'action': 227,\n",
              "             'series': 228,\n",
              "             'They': 229,\n",
              "             'always': 230,\n",
              "             'may': 231,\n",
              "             'right': 232,\n",
              "             'role': 233,\n",
              "             'gets': 234,\n",
              "             'saw': 235,\n",
              "             'original': 236,\n",
              "             'comedy': 237,\n",
              "             'almost': 238,\n",
              "             'You': 239,\n",
              "             'both': 240,\n",
              "             'without': 241,\n",
              "             'whole': 242,\n",
              "             'least': 243,\n",
              "             'times': 244,\n",
              "             'music': 245,\n",
              "             'done': 246,\n",
              "             'interesting': 247,\n",
              "             'big': 248,\n",
              "             'bit': 249,\n",
              "             'feel': 250,\n",
              "             'come': 251,\n",
              "             'guy': 252,\n",
              "             'point': 253,\n",
              "             'new': 254,\n",
              "             'script': 255,\n",
              "             'minutes': 256,\n",
              "             'far': 257,\n",
              "             'might': 258,\n",
              "             'anything': 259,\n",
              "             'am': 260,\n",
              "             'making': 261,\n",
              "             'What': 262,\n",
              "             'kind': 263,\n",
              "             'performance': 264,\n",
              "             'family': 265,\n",
              "             'TV': 266,\n",
              "             \"'ll\": 267,\n",
              "             'probably': 268,\n",
              "             'As': 269,\n",
              "             'away': 270,\n",
              "             'found': 271,\n",
              "             'She': 272,\n",
              "             'played': 273,\n",
              "             'hard': 274,\n",
              "             'last': 275,\n",
              "             'since': 276,\n",
              "             'rather': 277,\n",
              "             'fun': 278,\n",
              "             'woman': 279,\n",
              "             'worst': 280,\n",
              "             'girl': 281,\n",
              "             'trying': 282,\n",
              "             'each': 283,\n",
              "             'screen': 284,\n",
              "             'DVD': 285,\n",
              "             'course': 286,\n",
              "             'anyone': 287,\n",
              "             'looking': 288,\n",
              "             'That': 289,\n",
              "             'believe': 290,\n",
              "             'comes': 291,\n",
              "             'put': 292,\n",
              "             'our': 293,\n",
              "             'goes': 294,\n",
              "             'American': 295,\n",
              "             'yet': 296,\n",
              "             'shows': 297,\n",
              "             'ending': 298,\n",
              "             'especially': 299,\n",
              "             'sense': 300,\n",
              "             'book': 301,\n",
              "             'different': 302,\n",
              "             'main': 303,\n",
              "             'set': 304,\n",
              "             'watched': 305,\n",
              "             'worth': 306,\n",
              "             'sure': 307,\n",
              "             'place': 308,\n",
              "             'reason': 309,\n",
              "             '/>This': 310,\n",
              "             'looks': 311,\n",
              "             'effects': 312,\n",
              "             'actor': 313,\n",
              "             \"'d\": 314,\n",
              "             'play': 315,\n",
              "             'having': 316,\n",
              "             'plays': 317,\n",
              "             '10': 318,\n",
              "             'said': 319,\n",
              "             'money': 320,\n",
              "             'job': 321,\n",
              "             'day': 322,\n",
              "             'When': 323,\n",
              "             'seem': 324,\n",
              "             'So': 325,\n",
              "             '2': 326,\n",
              "             'takes': 327,\n",
              "             'true': 328,\n",
              "             'three': 329,\n",
              "             'together': 330,\n",
              "             'someone': 331,\n",
              "             'audience': 332,\n",
              "             'half': 333,\n",
              "             'left': 334,\n",
              "             'John': 335,\n",
              "             'himself': 336,\n",
              "             'wife': 337,\n",
              "             'version': 338,\n",
              "             'everything': 339,\n",
              "             'idea': 340,\n",
              "             'special': 341,\n",
              "             'during': 342,\n",
              "             'shot': 343,\n",
              "             'beautiful': 344,\n",
              "             'seeing': 345,\n",
              "             'One': 346,\n",
              "             'else': 347,\n",
              "             'fan': 348,\n",
              "             'everyone': 349,\n",
              "             'year': 350,\n",
              "             'once': 351,\n",
              "             'used': 352,\n",
              "             'high': 353,\n",
              "             'completely': 354,\n",
              "             'budget': 355,\n",
              "             'mind': 356,\n",
              "             'later': 357,\n",
              "             'excellent': 358,\n",
              "             'simply': 359,\n",
              "             'Not': 360,\n",
              "             'read': 361,\n",
              "             'We': 362,\n",
              "             'let': 363,\n",
              "             'short': 364,\n",
              "             'help': 365,\n",
              "             'poor': 366,\n",
              "             'less': 367,\n",
              "             'need': 368,\n",
              "             'nice': 369,\n",
              "             'For': 370,\n",
              "             'Hollywood': 371,\n",
              "             'use': 372,\n",
              "             'father': 373,\n",
              "             'camera': 374,\n",
              "             'top': 375,\n",
              "             'low': 376,\n",
              "             'kids': 377,\n",
              "             'line': 378,\n",
              "             'couple': 379,\n",
              "             'enjoy': 380,\n",
              "             'boring': 381,\n",
              "             'production': 382,\n",
              "             'try': 383,\n",
              "             'performances': 384,\n",
              "             'friends': 385,\n",
              "             'However': 386,\n",
              "             'rest': 387,\n",
              "             'start': 388,\n",
              "             'along': 389,\n",
              "             'second': 390,\n",
              "             'home': 391,\n",
              "             'recommend': 392,\n",
              "             'women': 393,\n",
              "             'My': 394,\n",
              "             '..': 395,\n",
              "             'truly': 396,\n",
              "             'classic': 397,\n",
              "             'stupid': 398,\n",
              "             'until': 399,\n",
              "             'men': 400,\n",
              "             'either': 401,\n",
              "             'given': 402,\n",
              "             'understand': 403,\n",
              "             'came': 404,\n",
              "             'wrong': 405,\n",
              "             'tell': 406,\n",
              "             'moments': 407,\n",
              "             'All': 408,\n",
              "             'video': 409,\n",
              "             'getting': 410,\n",
              "             'mean': 411,\n",
              "             'full': 412,\n",
              "             'death': 413,\n",
              "             'night': 414,\n",
              "             'sex': 415,\n",
              "             '/>It': 416,\n",
              "             'person': 417,\n",
              "             'instead': 418,\n",
              "             'style': 419,\n",
              "             'gives': 420,\n",
              "             'itself': 421,\n",
              "             'playing': 422,\n",
              "             'school': 423,\n",
              "             'face': 424,\n",
              "             'keep': 425,\n",
              "             'doing': 426,\n",
              "             'remember': 427,\n",
              "             'name': 428,\n",
              "             'war': 429,\n",
              "             'awful': 430,\n",
              "             'however': 431,\n",
              "             'maybe': 432,\n",
              "             'next': 433,\n",
              "             'small': 434,\n",
              "             'black': 435,\n",
              "             'perfect': 436,\n",
              "             'wonderful': 437,\n",
              "             'human': 438,\n",
              "             'although': 439,\n",
              "             'terrible': 440,\n",
              "             'often': 441,\n",
              "             'others': 442,\n",
              "             'become': 443,\n",
              "             'dialogue': 444,\n",
              "             'went': 445,\n",
              "             'piece': 446,\n",
              "             'written': 447,\n",
              "             'lines': 448,\n",
              "             'early': 449,\n",
              "             'No': 450,\n",
              "             'house': 451,\n",
              "             'sort': 452,\n",
              "             'episode': 453,\n",
              "             'THE': 454,\n",
              "             'felt': 455,\n",
              "             'head': 456,\n",
              "             'called': 457,\n",
              "             'star': 458,\n",
              "             'children': 459,\n",
              "             'laugh': 460,\n",
              "             'liked': 461,\n",
              "             'absolutely': 462,\n",
              "             'stars': 463,\n",
              "             'friend': 464,\n",
              "             'live': 465,\n",
              "             'supposed': 466,\n",
              "             'certainly': 467,\n",
              "             'entertaining': 468,\n",
              "             'title': 469,\n",
              "             'mother': 470,\n",
              "             'entire': 471,\n",
              "             'case': 472,\n",
              "             'seemed': 473,\n",
              "             'After': 474,\n",
              "             'At': 475,\n",
              "             'loved': 476,\n",
              "             'Even': 477,\n",
              "             'Do': 478,\n",
              "             'problem': 479,\n",
              "             '3': 480,\n",
              "             'wanted': 481,\n",
              "             'His': 482,\n",
              "             'worse': 483,\n",
              "             'beginning': 484,\n",
              "             'waste': 485,\n",
              "             'Well': 486,\n",
              "             'against': 487,\n",
              "             'definitely': 488,\n",
              "             'care': 489,\n",
              "             'boy': 490,\n",
              "             'guys': 491,\n",
              "             'drama': 492,\n",
              "             'several': 493,\n",
              "             'picture': 494,\n",
              "             'humor': 495,\n",
              "             'based': 496,\n",
              "             'becomes': 497,\n",
              "             'able': 498,\n",
              "             'hope': 499,\n",
              "             'lead': 500,\n",
              "             'cinema': 501,\n",
              "             'under': 502,\n",
              "             'totally': 503,\n",
              "             'sound': 504,\n",
              "             'To': 505,\n",
              "             'turn': 506,\n",
              "             'already': 507,\n",
              "             'wo': 508,\n",
              "             'example': 509,\n",
              "             'dead': 510,\n",
              "             'direction': 511,\n",
              "             'guess': 512,\n",
              "             'game': 513,\n",
              "             'fans': 514,\n",
              "             'wants': 515,\n",
              "             '....': 516,\n",
              "             'lost': 517,\n",
              "             'quality': 518,\n",
              "             '\\x96': 519,\n",
              "             'fine': 520,\n",
              "             'lives': 521,\n",
              "             'Michael': 522,\n",
              "             'son': 523,\n",
              "             'tries': 524,\n",
              "             'enjoyed': 525,\n",
              "             'gave': 526,\n",
              "             'side': 527,\n",
              "             'flick': 528,\n",
              "             'works': 529,\n",
              "             '<br': 530,\n",
              "             'final': 531,\n",
              "             '1': 532,\n",
              "             'history': 533,\n",
              "             'car': 534,\n",
              "             'Why': 535,\n",
              "             'writing': 536,\n",
              "             'matter': 537,\n",
              "             'viewer': 538,\n",
              "             'past': 539,\n",
              "             'town': 540,\n",
              "             'parts': 541,\n",
              "             'perhaps': 542,\n",
              "             'Also': 543,\n",
              "             'throughout': 544,\n",
              "             'genre': 545,\n",
              "             'expect': 546,\n",
              "             'amazing': 547,\n",
              "             'finally': 548,\n",
              "             'heart': 549,\n",
              "             'horrible': 550,\n",
              "             'hand': 551,\n",
              "             'Then': 552,\n",
              "             'close': 553,\n",
              "             'act': 554,\n",
              "             'behind': 555,\n",
              "             'turns': 556,\n",
              "             'New': 557,\n",
              "             'How': 558,\n",
              "             'favorite': 559,\n",
              "             'days': 560,\n",
              "             'killer': 561,\n",
              "             'late': 562,\n",
              "             'group': 563,\n",
              "             'killed': 564,\n",
              "             'today': 565,\n",
              "             'starts': 566,\n",
              "             'known': 567,\n",
              "             'directed': 568,\n",
              "             'themselves': 569,\n",
              "             'brilliant': 570,\n",
              "             'decent': 571,\n",
              "             'child': 572,\n",
              "             'says': 573,\n",
              "             'myself': 574,\n",
              "             'took': 575,\n",
              "             'While': 576,\n",
              "             'type': 577,\n",
              "             'stuff': 578,\n",
              "             'Of': 579,\n",
              "             'art': 580,\n",
              "             'etc': 581,\n",
              "             'run': 582,\n",
              "             'thinking': 583,\n",
              "             'evil': 584,\n",
              "             'heard': 585,\n",
              "             'eyes': 586,\n",
              "             'self': 587,\n",
              "             'kill': 588,\n",
              "             'happens': 589,\n",
              "             'daughter': 590,\n",
              "             'hour': 591,\n",
              "             'Some': 592,\n",
              "             'girls': 593,\n",
              "             'voice': 594,\n",
              "             'kid': 595,\n",
              "             'told': 596,\n",
              "             'feeling': 597,\n",
              "             '>': 598,\n",
              "             'slow': 599,\n",
              "             'white': 600,\n",
              "             'dark': 601,\n",
              "             'experience': 602,\n",
              "             'moment': 603,\n",
              "             'actress': 604,\n",
              "             'stop': 605,\n",
              "             'extremely': 606,\n",
              "             'Mr.': 607,\n",
              "             'involved': 608,\n",
              "             'lack': 609,\n",
              "             'coming': 610,\n",
              "             'score': 611,\n",
              "             'Now': 612,\n",
              "             'complete': 613,\n",
              "             'shown': 614,\n",
              "             'fight': 615,\n",
              "             'attempt': 616,\n",
              "             'soon': 617,\n",
              "             'obviously': 618,\n",
              "             'leave': 619,\n",
              "             'writer': 620,\n",
              "             'roles': 621,\n",
              "             'particularly': 622,\n",
              "             'serious': 623,\n",
              "             'violence': 624,\n",
              "             'happened': 625,\n",
              "             'looked': 626,\n",
              "             'hit': 627,\n",
              "             'chance': 628,\n",
              "             'stories': 629,\n",
              "             'David': 630,\n",
              "             'strong': 631,\n",
              "             'including': 632,\n",
              "             'simple': 633,\n",
              "             'hilarious': 634,\n",
              "             'obvious': 635,\n",
              "             'Just': 636,\n",
              "             'James': 637,\n",
              "             'ago': 638,\n",
              "             'taken': 639,\n",
              "             'husband': 640,\n",
              "             'opening': 641,\n",
              "             'English': 642,\n",
              "             'jokes': 643,\n",
              "             'wonder': 644,\n",
              "             'happen': 645,\n",
              "             'across': 646,\n",
              "             'Robert': 647,\n",
              "             'With': 648,\n",
              "             'interest': 649,\n",
              "             '/>In': 650,\n",
              "             'released': 651,\n",
              "             'hero': 652,\n",
              "             'sometimes': 653,\n",
              "             'exactly': 654,\n",
              "             'highly': 655,\n",
              "             'documentary': 656,\n",
              "             'crap': 657,\n",
              "             'song': 658,\n",
              "             '/>There': 659,\n",
              "             'cool': 660,\n",
              "             'except': 661,\n",
              "             'cut': 662,\n",
              "             'whose': 663,\n",
              "             '/>If': 664,\n",
              "             'career': 665,\n",
              "             'reality': 666,\n",
              "             'murder': 667,\n",
              "             'talent': 668,\n",
              "             'annoying': 669,\n",
              "             'brother': 670,\n",
              "             'relationship': 671,\n",
              "             'turned': 672,\n",
              "             'shots': 673,\n",
              "             'view': 674,\n",
              "             'sad': 675,\n",
              "             'cinematography': 676,\n",
              "             'important': 677,\n",
              "             'Man': 678,\n",
              "             'police': 679,\n",
              "             'save': 680,\n",
              "             'huge': 681,\n",
              "             'hours': 682,\n",
              "             'knew': 683,\n",
              "             'started': 684,\n",
              "             'opinion': 685,\n",
              "             'level': 686,\n",
              "             'gore': 687,\n",
              "             'ridiculous': 688,\n",
              "             'number': 689,\n",
              "             'living': 690,\n",
              "             'usual': 691,\n",
              "             'word': 692,\n",
              "             'novel': 693,\n",
              "             'saying': 694,\n",
              "             'somewhat': 695,\n",
              "             'running': 696,\n",
              "             'call': 697,\n",
              "             'light': 698,\n",
              "             'possible': 699,\n",
              "             'usually': 700,\n",
              "             'despite': 701,\n",
              "             'change': 702,\n",
              "             'taking': 703,\n",
              "             'ends': 704,\n",
              "             'knows': 705,\n",
              "             'order': 706,\n",
              "             '5': 707,\n",
              "             'yourself': 708,\n",
              "             'alone': 709,\n",
              "             'finds': 710,\n",
              "             'female': 711,\n",
              "             'local': 712,\n",
              "             'age': 713,\n",
              "             '4': 714,\n",
              "             'non': 715,\n",
              "             'wish': 716,\n",
              "             'Oh': 717,\n",
              "             'words': 718,\n",
              "             'body': 719,\n",
              "             'cheap': 720,\n",
              "             'single': 721,\n",
              "             'attention': 722,\n",
              "             'talking': 723,\n",
              "             'silly': 724,\n",
              "             'country': 725,\n",
              "             'sequence': 726,\n",
              "             'middle': 727,\n",
              "             'problems': 728,\n",
              "             'OK': 729,\n",
              "             'modern': 730,\n",
              "             'ones': 731,\n",
              "             'blood': 732,\n",
              "             'disappointed': 733,\n",
              "             'British': 734,\n",
              "             'room': 735,\n",
              "             'episodes': 736,\n",
              "             'musical': 737,\n",
              "             'events': 738,\n",
              "             'tells': 739,\n",
              "             'mostly': 740,\n",
              "             'appears': 741,\n",
              "             'it.<br': 742,\n",
              "             'predictable': 743,\n",
              "             'television': 744,\n",
              "             'Jack': 745,\n",
              "             'comic': 746,\n",
              "             'due': 747,\n",
              "             'similar': 748,\n",
              "             'Although': 749,\n",
              "             'beyond': 750,\n",
              "             'giving': 751,\n",
              "             'power': 752,\n",
              "             'On': 753,\n",
              "             'upon': 754,\n",
              "             'major': 755,\n",
              "             'message': 756,\n",
              "             'moving': 757,\n",
              "             'straight': 758,\n",
              "             'review': 759,\n",
              "             'songs': 760,\n",
              "             '/>But': 761,\n",
              "             'scary': 762,\n",
              "             'class': 763,\n",
              "             'seriously': 764,\n",
              "             'happy': 765,\n",
              "             'thriller': 766,\n",
              "             'dialog': 767,\n",
              "             'soundtrack': 768,\n",
              "             'romantic': 769,\n",
              "             'mention': 770,\n",
              "             'bring': 771,\n",
              "             'clearly': 772,\n",
              "             'certain': 773,\n",
              "             'four': 774,\n",
              "             'strange': 775,\n",
              "             'easily': 776,\n",
              "             'enjoyable': 777,\n",
              "             'release': 778,\n",
              "             'near': 779,\n",
              "             'clear': 780,\n",
              "             'working': 781,\n",
              "             'George': 782,\n",
              "             'sets': 783,\n",
              "             'falls': 784,\n",
              "             'none': 785,\n",
              "             'hell': 786,\n",
              "             'named': 787,\n",
              "             'effort': 788,\n",
              "             'above': 789,\n",
              "             'needs': 790,\n",
              "             'surprised': 791,\n",
              "             'sequel': 792,\n",
              "             'theme': 793,\n",
              "             'tried': 794,\n",
              "             'supporting': 795,\n",
              "             'hate': 796,\n",
              "             'kept': 797,\n",
              "             'God': 798,\n",
              "             'dull': 799,\n",
              "             'typical': 800,\n",
              "             'ways': 801,\n",
              "             'future': 802,\n",
              "             'bunch': 803,\n",
              "             'subject': 804,\n",
              "             'within': 805,\n",
              "             'famous': 806,\n",
              "             'fast': 807,\n",
              "             'entertainment': 808,\n",
              "             'feels': 809,\n",
              "             '$': 810,\n",
              "             'fall': 811,\n",
              "             'Oscar': 812,\n",
              "             'talk': 813,\n",
              "             'editing': 814,\n",
              "             'stand': 815,\n",
              "             'ten': 816,\n",
              "             'doubt': 817,\n",
              "             'feature': 818,\n",
              "             'means': 819,\n",
              "             'team': 820,\n",
              "             'brought': 821,\n",
              "             'five': 822,\n",
              "             'showing': 823,\n",
              "             'realistic': 824,\n",
              "             'among': 825,\n",
              "             'comments': 826,\n",
              "             'movie.<br': 827,\n",
              "             'Peter': 828,\n",
              "             'filmed': 829,\n",
              "             'herself': 830,\n",
              "             'parents': 831,\n",
              "             'using': 832,\n",
              "             'elements': 833,\n",
              "             'tale': 834,\n",
              "             'suspense': 835,\n",
              "             'points': 836,\n",
              "             'First': 837,\n",
              "             'form': 838,\n",
              "             'storyline': 839,\n",
              "             'Maybe': 840,\n",
              "             'Richard': 841,\n",
              "             '/>A': 842,\n",
              "             'rating': 843,\n",
              "             'viewers': 844,\n",
              "             'French': 845,\n",
              "             'deal': 846,\n",
              "             'whether': 847,\n",
              "             'basically': 848,\n",
              "             'Yes': 849,\n",
              "             'material': 850,\n",
              "             'move': 851,\n",
              "             'easy': 852,\n",
              "             'nearly': 853,\n",
              "             'actual': 854,\n",
              "             'leads': 855,\n",
              "             'sister': 856,\n",
              "             'believable': 857,\n",
              "             'learn': 858,\n",
              "             'killing': 859,\n",
              "             'expected': 860,\n",
              "             'From': 861,\n",
              "             'hear': 862,\n",
              "             'viewing': 863,\n",
              "             'overall': 864,\n",
              "             'Paul': 865,\n",
              "             'average': 866,\n",
              "             'York': 867,\n",
              "             'buy': 868,\n",
              "             'B': 869,\n",
              "             'city': 870,\n",
              "             'add': 871,\n",
              "             'eye': 872,\n",
              "             'sit': 873,\n",
              "             'America': 874,\n",
              "             'figure': 875,\n",
              "             'follow': 876,\n",
              "             'sequences': 877,\n",
              "             'crime': 878,\n",
              "             'animation': 879,\n",
              "             'particular': 880,\n",
              "             'greatest': 881,\n",
              "             'reviews': 882,\n",
              "             'decided': 883,\n",
              "             'Its': 884,\n",
              "             'lots': 885,\n",
              "             'weak': 886,\n",
              "             'poorly': 887,\n",
              "             'Is': 888,\n",
              "             'die': 889,\n",
              "             'stay': 890,\n",
              "             'apparently': 891,\n",
              "             'surprise': 892,\n",
              "             'period': 893,\n",
              "             'open': 894,\n",
              "             'Her': 895,\n",
              "             'forced': 896,\n",
              "             'theater': 897,\n",
              "             'begins': 898,\n",
              "             'Who': 899,\n",
              "             'monster': 900,\n",
              "             'situation': 901,\n",
              "             'needed': 902,\n",
              "             'film.<br': 903,\n",
              "             'Unfortunately': 904,\n",
              "             'premise': 905,\n",
              "             'Tom': 906,\n",
              "             'fantastic': 907,\n",
              "             '/>As': 908,\n",
              "             'became': 909,\n",
              "             'difficult': 910,\n",
              "             'minute': 911,\n",
              "             'leaves': 912,\n",
              "             'meets': 913,\n",
              "             'gone': 914,\n",
              "             'atmosphere': 915,\n",
              "             'credits': 916,\n",
              "             '/>And': 917,\n",
              "             'War': 918,\n",
              "             'write': 919,\n",
              "             'free': 920,\n",
              "             '20': 921,\n",
              "             'emotional': 922,\n",
              "             'acted': 923,\n",
              "             'crew': 924,\n",
              "             'Disney': 925,\n",
              "             'sexual': 926,\n",
              "             'whom': 927,\n",
              "             'begin': 928,\n",
              "             're': 929,\n",
              "             'Most': 930,\n",
              "             'rent': 931,\n",
              "             'society': 932,\n",
              "             'dog': 933,\n",
              "             'footage': 934,\n",
              "             'An': 935,\n",
              "             'Like': 936,\n",
              "             'somehow': 937,\n",
              "             'truth': 938,\n",
              "             'features': 939,\n",
              "             'King': 940,\n",
              "             'previous': 941,\n",
              "             'yes': 942,\n",
              "             'These': 943,\n",
              "             'NOT': 944,\n",
              "             'gay': 945,\n",
              "             'keeps': 946,\n",
              "             'male': 947,\n",
              "             'forward': 948,\n",
              "             'worked': 949,\n",
              "             'appear': 950,\n",
              "             'interested': 951,\n",
              "             'question': 952,\n",
              "             'perfectly': 953,\n",
              "             'lame': 954,\n",
              "             'memorable': 955,\n",
              "             'Lee': 956,\n",
              "             'comment': 957,\n",
              "             'forget': 958,\n",
              "             'nature': 959,\n",
              "             'unique': 960,\n",
              "             'laughs': 961,\n",
              "             'possibly': 962,\n",
              "             'badly': 963,\n",
              "             'personal': 964,\n",
              "             'Dr.': 965,\n",
              "             'setting': 966,\n",
              "             'stage': 967,\n",
              "             'wait': 968,\n",
              "             'box': 969,\n",
              "             'Japanese': 970,\n",
              "             'cop': 971,\n",
              "             'dramatic': 972,\n",
              "             'mystery': 973,\n",
              "             'deep': 974,\n",
              "             'rate': 975,\n",
              "             'romance': 976,\n",
              "             'earlier': 977,\n",
              "             'girlfriend': 978,\n",
              "             'dance': 979,\n",
              "             'older': 980,\n",
              "             'quickly': 981,\n",
              "             'reading': 982,\n",
              "             'result': 983,\n",
              "             'superb': 984,\n",
              "             'powerful': 985,\n",
              "             'realize': 986,\n",
              "             'admit': 987,\n",
              "             'brings': 988,\n",
              "             'space': 989,\n",
              "             'weird': 990,\n",
              "             'screenplay': 991,\n",
              "             'background': 992,\n",
              "             'cheesy': 993,\n",
              "             'copy': 994,\n",
              "             'joke': 995,\n",
              "             'portrayed': 996,\n",
              "             'masterpiece': 997,\n",
              "             'please': 998,\n",
              "             'writers': 999,\n",
              "             ...})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDrZbyjcuW9v"
      },
      "source": [
        "- The indexes are given randomly to each unique word.\n",
        "- Let us now instantiate an iterator that iterates through each and every text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cATiuZ7orZP9"
      },
      "source": [
        "# Set batch size\n",
        "BATCH_SIZE = 128\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Setting up a Device based on GPU availability.\n",
        "\n",
        "#Instantiate an iterator.\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
        "    (train_ds, val_ds), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP9zTVzOv7td"
      },
      "source": [
        "## Building the Model\n",
        "- Let us choose a LSTM Architecture as a model and then try to stack word embeddings layer with that one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCQRF59-YyY3"
      },
      "source": [
        "class LSTM_Classifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        # Using Embedding Layer.\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        # Using Bidirectional LSTM Layer.\n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim) # Hidden dimension is multiplied by 2 because of Bidirectional.\n",
        "        \n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        # output = [sent len, batch size, hid dim * num directions]\n",
        "        # output over padding tokens are zero tensors\n",
        "        \n",
        "        # hidden = [num layers * num directions, batch size, hid dim]\n",
        "        # cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        # and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        output = self.fc1(hidden)\n",
        "        output = self.dropout(self.fc2(output))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMs2S8YdtdaF"
      },
      "source": [
        "- Let us define our **HyperParameters** for the current Architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3heNSvryuC"
      },
      "source": [
        "# Setting up the Hyperparameters.\n",
        "num_epochs = 5 # Num of times to make propagation.\n",
        "learning_rate = 0.001 # Setting up a Learning rate.\n",
        "\n",
        "INPUT_DIM = len(text_field.vocab) # Desired or fixed size of the Vocabulary of the Text Corpus.\n",
        "EMBEDDING_DIM = 100 # Number of Embedding Dimension we would want to give to a single token of a text.\n",
        "HIDDEN_DIM = 256 # Number of Hidden cells or (Unoficially can be regarded to Neurons).\n",
        "OUTPUT_DIM = 1 # Number of output neurons. Using 1 for binary classifier problem.\n",
        "N_LAYERS = 2 # Number of Neural Network Layers.\n",
        "BIDIRECTIONAL = True # If given true then applies bidirectional RNN\n",
        "DROPOUT = 0.2\n",
        "PAD_IDX = text_field.vocab.stoi[text_field.pad_token] # padding index sizes."
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZIPUiUPtldi"
      },
      "source": [
        "- Now let us instantiate an object for our RNN Model class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgXDA-vHtTuo"
      },
      "source": [
        "# Declaring a LSTM Biderectional Model.\n",
        "lstm_model = LSTM_Classifier(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xIBI_PyuPY9"
      },
      "source": [
        "- Let us have a Look at our Model Parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfITe7hRYygb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd3e40f-2ba5-4b52-8fb7-c06fbfaffc28"
      },
      "source": [
        "# Printing the Model architecture\n",
        "print(lstm_model)\n",
        "\n",
        "# Counting the No. of Model parameters\n",
        "sum_parameters = 0\n",
        "for p in lstm_model.parameters():\n",
        "    sum_parameters = sum_parameters + p.numel()\n",
        "    \n",
        "print(f'The model has {sum_parameters} trainable parameters')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM_Classifier(\n",
            "  (embedding): Embedding(42372, 100, padding_idx=1)\n",
            "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.2, bidirectional=True)\n",
            "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "The model has 6678929 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u-y_knQuTxn"
      },
      "source": [
        "- Let us have a look at our Glove Weights and padded Sequences.\n",
        "- Also lets look at the weights produced by the GloVe embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q47IYKktx1cl",
        "outputId": "8dd66e21-ed8f-47f1-a24b-15ed00b076f5"
      },
      "source": [
        "pretrained_embeddings = text_field.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)\n",
        "lstm_model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([42372, 100])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.4335,  0.1364, -0.0564,  ...,  0.5828, -0.5681, -0.3139]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7trVt7IuTe0",
        "outputId": "8d23a2d2-c084-4c05-fb23-0bdca38c180c"
      },
      "source": [
        "lstm_model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(lstm_model.embedding.weight.data)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.4335,  0.1364, -0.0564,  ...,  0.5828, -0.5681, -0.3139]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XIzGPivu-Ow"
      },
      "source": [
        "- Let us set some more of the Important Model Parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLWeKzLWKXBV"
      },
      "source": [
        "# Setting Model to current Device.\n",
        "lstm_model.to(device) #CPU to GPU\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Defining a Metric that calculates the Accuracy.\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdF3fi68vKC3"
      },
      "source": [
        "# Defining Training and Evaluating Methods\n",
        "- We would be defining some functions that can train our model and also evaluate the performane."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZaDiZU5Kta6"
      },
      "source": [
        "# A Function that can Train our model at each and every epoch. \n",
        "\n",
        "def train(model, iterator):\n",
        "    \n",
        "    epoch_loss = 0 # Instantiating the loss as zero.\n",
        "    epoch_accuracy = 0 # Instantiating the accuaracy accuracy.\n",
        "    \n",
        "    model.train() # This actually lets the model to work with dropout.\n",
        "    \n",
        "    for batch in iterator: # Iterating via For loop the Data_Iterator.\n",
        "        text, text_lengths = batch.review # Unpacking text and its lengths from a single batch.\n",
        "        \n",
        "        optimizer.zero_grad() \n",
        "        predictions = model(text, text_lengths.cpu()).squeeze(1) # Setting lengths to CPU and Squeezing the model for a while.\n",
        "        batch_loss = criterion(predictions, batch.sentiment) # Calculating the Loss.\n",
        "        batch_accuracy = binary_accuracy(predictions, batch.sentiment) # Calculating the Accuracy.\n",
        "\n",
        "        batch_loss.backward() # BackPropagate Step\n",
        "        optimizer.step() # Setting Optimizer a step ahead\n",
        "        \n",
        "        epoch_loss += batch_loss.item()\n",
        "        epoch_accuracy += batch_accuracy.item()\n",
        "        \n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator) # Returning loss and accuracy"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS9EhbjRQTb5"
      },
      "source": [
        "# A function that Evaluates the performance of the model at each epoch.\n",
        "\n",
        "def evaluate(model, iterator):\n",
        "    \n",
        "    epoch_loss = 0 # Instantiating the loss as zero.\n",
        "    epoch_accuracy = 0 # Instantiating the accuaracy accuracy.\n",
        "    \n",
        "    model.eval() # Unlocking all the Nodes to get rid of Dropout.\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, text_lengths = batch.review\n",
        "            predictions = model(text, text_lengths.cpu()).squeeze(1)\n",
        "            loss = criterion(predictions, batch.sentiment)\n",
        "            acc = binary_accuracy(predictions, batch.sentiment)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_accuracy += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator) ,epoch_accuracy / len(iterator)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YphjNKCXvkB1"
      },
      "source": [
        "# Training our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBr8ga6CQTiY",
        "outputId": "bd613161-6ae9-4fb6-902e-cc796bb7161c"
      },
      "source": [
        "t = time.time()\n",
        "loss=[]\n",
        "acc=[]\n",
        "val_acc=[]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    train_loss, train_acc = train(lstm_model, train_iterator)\n",
        "    valid_loss, valid_acc = evaluate(lstm_model, valid_iterator)\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    loss.append(train_loss)\n",
        "    acc.append(train_acc)\n",
        "    val_acc.append(valid_acc)\n",
        "    \n",
        "print(f'time:{time.time()-t:.3f}')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.619 | Train Acc: 63.77%\n",
            "\tValid Loss: 0.468 | Valid Acc: 79.50%\n",
            "\tTrain Loss: 0.538 | Train Acc: 70.60%\n",
            "\tValid Loss: 0.367 | Valid Acc: 84.43%\n",
            "\tTrain Loss: 0.373 | Train Acc: 80.49%\n",
            "\tValid Loss: 0.365 | Valid Acc: 84.44%\n",
            "\tTrain Loss: 0.289 | Train Acc: 84.17%\n",
            "\tValid Loss: 0.252 | Valid Acc: 89.98%\n",
            "\tTrain Loss: 0.247 | Train Acc: 86.01%\n",
            "\tValid Loss: 0.266 | Valid Acc: 89.89%\n",
            "time:318.019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLh_lNSH0AwX"
      },
      "source": [
        "# Visualizing our Results.\n",
        "- Let us normalize all our Scores and try to visualize the results and try to analyze and choose best epoch for the LSTM Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "B0pggCx70AmB",
        "outputId": "deb5d7bc-c0fc-43a8-c61f-4a6a7c1c18de"
      },
      "source": [
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Normalised measure of loss and accuracy\")\n",
        "x_len=list(range(len(acc)))\n",
        "plt.axis([0, max(x_len), 0, 1])\n",
        "plt.title('result of LSTM')\n",
        "loss=np.asarray(loss)/max(loss)\n",
        "plt.plot(x_len, loss, 'r',label=\"Train loss\")\n",
        "plt.plot(x_len, acc, 'b', label=\"Training accuracy\")\n",
        "plt.plot(x_len, val_acc, 'g', label=\"validation accuracy\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.2)\n",
        "plt.show"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5I5G4nM1A6G"
      },
      "source": [
        "## Conclusion\n",
        "- Looks like we can train the model for **some more epochs** to get perfect balance for the Bias Variance parameter.\n",
        "- Also these are the results with embedding length of around **100 Dimesions** and we can improve it alot by using **200 Dimensions**.\n",
        "# THANK YOU !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TGq6sXz0ksn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}